{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats as s\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights = 'imagenet', include_top = False)\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(25088,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(11, activation='softmax'))\n",
    "model.load_weights(\"weight.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset/0_656_org_voi.wav.png</td>\n",
       "      <td>org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset/2_275_pia_tru.wav.png</td>\n",
       "      <td>pia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataset/2_709_gac_gel.wav.png</td>\n",
       "      <td>gac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset/0_506_gac_vio.wav.png</td>\n",
       "      <td>gac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset/0_352_gel_sax.wav.png</td>\n",
       "      <td>gel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image label\n",
       "0  Dataset/0_656_org_voi.wav.png   org\n",
       "1  Dataset/2_275_pia_tru.wav.png   pia\n",
       "2  Dataset/2_709_gac_gel.wav.png   gac\n",
       "3  Dataset/0_506_gac_vio.wav.png   gac\n",
       "4  Dataset/0_352_gel_sax.wav.png   gel"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = test['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = []\n",
    "#Get the ground truth values of the testing data\n",
    "actual = test['label']\n",
    "for i in range(len(test_imgs)):\n",
    "    img = image.load_img(test_imgs[i], target_size=(224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    #Extract features from the base model\n",
    "    pre = []\n",
    "    pre.append(img)\n",
    "    pre = np.array(pre)\n",
    "    img_features = base_model.predict(pre)\n",
    "    img_features = img_features.reshape(pre.shape[0], 7*7*512)\n",
    "    #Input the extracted features to the model we built\n",
    "    prediction = model.predict_classes(img_features)\n",
    "    predict.append(y.columns.values[s.mode(prediction)[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is %54.6916890080429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(predict, actual)*100\n",
    "print(\"The accuracy of the model is %\"+str(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
